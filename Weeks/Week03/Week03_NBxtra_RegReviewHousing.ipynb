{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Linear Regression\n\nHousing Prices Competition for Kaggle Learn Users:\n* https://www.kaggle.com/c/home-data-for-ml-course/data"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "house_data = pd.read_csv('https://raw.githubusercontent.com/benjum/UCLAX-23W-ML/main/Weeks/Week02/data/home-train.csv')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "house_data.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "house_data.info()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "h2 = house_data[['OverallQual','OverallCond','BedroomAbvGr','GrLivArea','SalePrice']].copy()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "h2.sample(10)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "sns.regplot(data=h2, x='OverallQual', y='SalePrice')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "sns.regplot(data=h2, x='OverallCond', y='SalePrice')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "sns.regplot(data=h2, x='BedroomAbvGr', y='SalePrice')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "sns.regplot(data=h2, x='GrLivArea', y='SalePrice')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Using one feature for simple linear regression"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n#from sklearn.preprocessing import StandardScaler"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X = h2[['GrLivArea']]\ny = h2['SalePrice']"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "#scaler = StandardScaler()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "#X_train = scaler.fit_transform(X_train)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "#X_test = scaler.transform(X_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "linear_regression = LinearRegression()\nmodel = linear_regression.fit(X_train, y_train)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y_pred = model.predict(X_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "df = pd.DataFrame({'test': y_test, 'predicted': y_pred})"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "df.sample(10)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Regression line"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.scatter(X_test, y_test)\nplt.plot(X_test, y_pred, c='r')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(\"Training score : \", linear_regression.score(X_train, y_train))\nprint(\"Testing score : \", linear_regression.score(X_test, y_test))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.metrics import r2_score, mean_squared_error"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "r2score = r2_score(y_test, y_pred)\nmsescore = mean_squared_error(y_test, y_pred)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(\"Testing score R2 : \", r2score)\nprint(\"Testing score StdDev : \", np.sqrt(msescore))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "theta_0 = linear_regression.coef_\ntheta_0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "intercept = linear_regression.intercept_\nintercept"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(y_pred, label=\"Prediction\")\nplt.plot(y_test.values, label=\"Actual\")\nplt.legend()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "plt.plot(y_test.values, y_pred, 'ko')\nplt.plot([0,600000],[0,600000])"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Using statsmodels and OLS instead of scikit-learn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "import statsmodels.api as sm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train[:5]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train = sm.add_constant(X_train)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train[:5]"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "model = sm.OLS(y_train, X_train).fit()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(model.summary())"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "theta_0, intercept"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Multiple Regression "
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "house_data.shape"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "target = house_data['SalePrice']\nfeatures = house_data.drop('SalePrice', axis=1)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "features.info()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "I'm only going to keep numerical columns for now."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "features = features.select_dtypes(include='number').copy()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "And I'm going to drop the columns that don't have 1460 non-null values."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "features = features.drop(['GarageYrBlt','MasVnrArea','LotFrontage'],axis=1)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "features.columns"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Yellowbrick\n\n* \"Yellowbrick extends the Scikit-Learn API to make model selection and hyperparameter tuning easier. Under the hood, it’s using Matplotlib.\"\n* https://www.scikit-yb.org/en/latest/"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "# Need to install yellowbrick if you don't have it"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from yellowbrick.target import FeatureCorrelation"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "visualizer = FeatureCorrelation(labels = list(features.columns), sort=True)\nvisualizer.fit(features, target)\nvisualizer.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Select K-Best features to predict price of houses"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Scikit-Learn has methods for selecting the \"best\" features.  For example, the following will use `f_regression` to do \"univariate linear regression tests returning F-statistic and p-values\" in order to select a set of best features.\n* [feature_selection with f_regression](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.feature_selection import SelectKBest, f_regression"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "best6 = SelectKBest(f_regression, k=6).fit(features, target)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "best6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "help(best6)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "best6.get_feature_names_out()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "best6.get_support()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "bestcolumns = features.columns[best6.get_support()]\nbestcolumns"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "myfeatures = features[bestcolumns]\nmyfeatures.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "myfeatures.describe()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Aside\n\nWhen we consider feature engineering later, we'll want to consider whether some of the variables are dependent.  And exactly what happens when we have multicollinearity of the variables.\n\nMulticollinearity may not have an effect on the predictive power of our model, but it can affect the variance of our coefficient estimates, lead to larger confidence intervals, and make it more difficult to interpret the predictors of our final model.\n\nHere we briefly show how to identify whether variables might suffer from collinearity by measuring the variance inflation factor (VIF) -- values of 1 are ignorable, < 5 are reasonable, and > 5 should be dealt with."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from statsmodels.stats.outliers_influence import variance_inflation_factor"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "myfeatures.values"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "vif = pd.DataFrame()\nvif['VIF'] = [round(variance_inflation_factor(myfeatures.values, i), 1) for i in range(myfeatures.shape[1])]\nvif['variable'] = myfeatures.columns"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "vif.sort_values(by='VIF', ascending=False)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Scaling"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Scaling of feature values is another feature engineering concept that we will need to contend with.\n\nFeature scaling can be necessary for applying certain algorithms, it may not matter at all in other cases, sometimes it can make algorithms run faster, it can give a better error surface shape, it can prevent optimization algorithms from getting stuck in local minima, it can reduce the collinearity of two variables, ....\n\nHere we have features that have very different scales, and we'll show scaling as a method to make their scales uniform, but we will return to this in more detail throughout the course."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.preprocessing import scale"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X = pd.DataFrame(data=scale(myfeatures), columns=myfeatures.columns)\ny = target"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X.describe()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.model_selection import train_test_split"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "**Wait!  Danger:**  we've scaled our data before doing the test/train split.  Information about the training set may therefore have leaked into the test set."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.preprocessing import StandardScaler"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X = pd.DataFrame(data=myfeatures, columns=myfeatures.columns)\ny = target"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X.describe()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.model_selection import train_test_split"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(X_train.mean())\nprint(X_train.std())\nprint(X_test.mean())\nprint(X_test.std())"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "print(np.concatenate((X_train,X_test)).mean())\nprint(np.concatenate((X_train,X_test)).std())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Ok, better."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.linear_model import LinearRegression"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "linear_regression = LinearRegression()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "linear_regression.fit(X_train, y_train)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "y_pred = linear_regression.predict(X_test)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "df = pd.DataFrame({'test': y_test, 'Predicted': y_pred})"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "df.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "from sklearn.metrics import r2_score, mean_squared_error"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "score = linear_regression.score(X_train, y_train)\nr2score = r2_score(y_test, y_pred)\nstddevscore = np.sqrt(mean_squared_error(y_test, y_pred))\n\nprint('Score: {}'.format(score))\nprint('r2_score: {}'.format(r2score))\nprint('stddev_score: {}'.format(stddevscore))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "linear_regression.coef_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "linear_regression.intercept_"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## The statsmodels way"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "X_train = sm.add_constant(X_train)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "ols = sm.OLS(y_train, X_train)\nmodel = ols.fit()\ny_pred = model.predict(X_train)\n\nmodel.summary()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "linear_regression.intercept_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "linear_regression.coef_"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Exercises\n\n* What happens if you don't do any scaling above for the case with best6 features.  Does the performance change?\n\n* Notice that two values don't appear to be statistically significant.... can you get just as good a result for only picking 4 values?\n\n* Also, try checking out a slightly different method for selecting features: mutual_info\n\n* Try using the full training set for training and using the 'test.csv' data to do the test."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": "visualizer = FeatureCorrelation(method='mutual_info-regression',\n                                labels = list(features.columns),\n                                sort=True)\nvisualizer.fit(features, target)\nvisualizer.show()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}